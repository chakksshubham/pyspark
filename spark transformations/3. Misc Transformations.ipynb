{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53910406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+---+-----------+-----------+\n",
      "|FirstName|LastName|Age|       City|DateOfBirth|\n",
      "+---------+--------+---+-----------+-----------+\n",
      "|    Emily|   Davis| 29|    Houston| 1996-12-25|\n",
      "|     Jane|   Smith| 34|Los Angeles| 2010-12-30|\n",
      "|     John|     Doe| 28|   New York| 2006-12-12|\n",
      "|  Michael| Johnson| 31|    Phoenix| 1998-12-31|\n",
      "|      Sam|   Brown| 22|    Chicago| 1984-12-20|\n",
      "+---------+--------+---+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creating quick dataframe\n",
    "# Uniform the year \n",
    "# Drop the Duplicates\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    spark = (\n",
    "        SparkSession.builder\n",
    "        .appName('mis transformations')\n",
    "        .master('local[*]')\n",
    "        .getOrCreate()\n",
    "    )\n",
    "\n",
    "    data = [\n",
    "        ('John', 'Doe', 28, 'New York',2006,12,12),\n",
    "        ('Jane', 'Smith', 34, 'Los Angeles',2010,15,12),\n",
    "        ('Sam', 'Brown', 22, 'Chicago',84,20,12),\n",
    "        ('Emily', 'Davis', 29, 'Houston',96,25,12),\n",
    "        ('Michael', 'Johnson', 31, 'Phoenix',98,31,12),\n",
    "        ('Jane', 'Smith', 34, 'Los Angeles',2010,30,12)\n",
    "    ]\n",
    "\n",
    "    schema = StructType([\n",
    "        StructField('FirstName',StringType()),\n",
    "        StructField('LastName',StringType()),\n",
    "        StructField('Age',IntegerType()),\n",
    "        StructField('City',StringType()),\n",
    "        StructField('Year',IntegerType()),\n",
    "        StructField('Day',IntegerType()),\n",
    "        StructField('Month',IntegerType())\n",
    "    ]\n",
    "    )\n",
    "\n",
    "    spark_df = spark.createDataFrame(\n",
    "        data,\n",
    "        schema = schema\n",
    "    )\n",
    "\n",
    "    # Rectifiy the Date issue; we can see the pattern that if the year is 2 digit then its mostly from 1900s\n",
    "\n",
    "    date_rectified_df = (\n",
    "        spark_df.withColumn(\n",
    "        'Year',\n",
    "        when(\n",
    "            length(col('Year')) == 2,\n",
    "            col('Year') + 1900\n",
    "        ).otherwise(\n",
    "            col('Year')\n",
    "        )\n",
    "    )\n",
    "    )\n",
    "\n",
    "    # Add a incremental unique id\n",
    "\n",
    "    unique_id_df = (\n",
    "        date_rectified_df.withColumn(\n",
    "            'UniqueID',\n",
    "            monotonically_increasing_id()\n",
    "        )\n",
    "    ).select(\n",
    "        'UniqueID',\n",
    "        'FirstName',\n",
    "        'LastName',\n",
    "        'Age',\n",
    "        'City',\n",
    "        'Year'\n",
    "    )\n",
    "\n",
    "    # Showing Type casting error\n",
    "    # Type casting is useful when we inherit the data from files with issues\n",
    "    # when we define the dataframe its good to create the schema as well as we created \n",
    "\n",
    "    data2 = [\n",
    "        ('John', 'Doe', 28, 'New York','2006'),\n",
    "        ('Jane', 'Smith', 34, 'Los Angeles','2010'),\n",
    "        ('Sam', 'Brown', 22, 'Chicago','84'),\n",
    "        ('Emily', 'Davis', 29, 'Houston','96'),\n",
    "        ('Michael', 'Johnson', 31, 'Phoenix','98'),\n",
    "        ('Jane', 'Smith', 34, 'Los Angeles','2010')\n",
    "    ]\n",
    "\n",
    "    spark_df2 = spark.createDataFrame(\n",
    "        data2,\n",
    "        ['FirstName','LastName','Age','City','Year']                \n",
    "        ).withColumn(\n",
    "            'Year',\n",
    "            when (\n",
    "                length(col('Year')) == 2,\n",
    "                col('Year') + 1900\n",
    "            ).otherwise(\n",
    "                col('Year')\n",
    "            )\n",
    "        )\n",
    "#+---------+--------+---+-----------+------+\n",
    "#|FirstName|LastName|Age|       City|  Year|\n",
    "#+---------+--------+---+-----------+------+\n",
    "#|     John|     Doe| 28|   New York|  2006|\n",
    "#|     Jane|   Smith| 34|Los Angeles|  2010|\n",
    "#|      Sam|   Brown| 22|    Chicago|1984.0|\n",
    "#|    Emily|   Davis| 29|    Houston|1996.0|\n",
    "#|  Michael| Johnson| 31|    Phoenix|1998.0|\n",
    "#|     Jane|   Smith| 34|Los Angeles|  2010|\n",
    "#+---------+--------+---+-----------+------+\n",
    "    # The transformation that happenend here as there incorrect datatype and automatic type promotion by spark\n",
    "    # The year is string when we performed arithmetic opetation spark sql engine prtomoted it to float and after opetation the column was demoted to string and decimals wasnt removed  \n",
    "    # Solution is the Casting method\n",
    "\n",
    "# 2 Ways:\n",
    "    # Casting so with transformation so Spark dooest automatically promote or demote the datatype\n",
    "\n",
    "    spark_df2 = spark.createDataFrame(\n",
    "        data2,\n",
    "        ['FirstName','LastName','Age','City','Year']                \n",
    "        ).withColumn(\n",
    "            'Year',\n",
    "            when (\n",
    "                length(col('Year')) == 2,\n",
    "                col('Year').cast(IntegerType()) + 1900\n",
    "            ).otherwise(\n",
    "                col('Year')\n",
    "            )\n",
    "        )\n",
    "\n",
    "# +---------+--------+---+-----------+----+\n",
    "# |FirstName|LastName|Age|       City|Year|\n",
    "# +---------+--------+---+-----------+----+\n",
    "# |     John|     Doe| 28|   New York|2006|\n",
    "# |     Jane|   Smith| 34|Los Angeles|2010|\n",
    "# |      Sam|   Brown| 22|    Chicago|1984|\n",
    "# |    Emily|   Davis| 29|    Houston|1996|\n",
    "# |  Michael| Johnson| 31|    Phoenix|1998|\n",
    "# |     Jane|   Smith| 34|Los Angeles|2010|\n",
    "# +---------+--------+---+-----------+----+\n",
    "    # You dont see the decimals anymore\n",
    "    # Recommended approach\n",
    "\n",
    "    # Second Approach Change the schema format with casting in the beginning post the defining of the dataframe\n",
    "    spark_df2 = spark.createDataFrame(\n",
    "    data2,\n",
    "    ['FirstName','LastName','Age','City','Year']                \n",
    "    ).withColumn(\n",
    "        'FirstName',col('FirstName').cast(StringType())\n",
    "    ).withColumn(\n",
    "        'LastName',col('LastName').cast(StringType())\n",
    "    ).withColumn(\n",
    "        'Age',col('Age').cast(IntegerType())\n",
    "    ).withColumn(\n",
    "        'City',col('City').cast(StringType())\n",
    "    ).withColumn(\n",
    "        'Year',col('Year').cast(IntegerType())\n",
    "    ).withColumn(\n",
    "        'Year',\n",
    "        when (\n",
    "            length(col('Year')) == 2,\n",
    "            col('Year') + 1900\n",
    "        ).otherwise(\n",
    "            col('Year')\n",
    "        )\n",
    "    )\n",
    "\n",
    "# +---------+--------+---+-----------+----+\n",
    "# |FirstName|LastName|Age|       City|Year|\n",
    "# +---------+--------+---+-----------+----+\n",
    "# |     John|     Doe| 28|   New York|2006|\n",
    "# |     Jane|   Smith| 34|Los Angeles|2010|\n",
    "# |      Sam|   Brown| 22|    Chicago|1984|\n",
    "# |    Emily|   Davis| 29|    Houston|1996|\n",
    "# |  Michael| Johnson| 31|    Phoenix|1998|\n",
    "# |     Jane|   Smith| 34|Los Angeles|2010|\n",
    "# +---------+--------+---+-----------+----+\n",
    "\n",
    "    # Adding and removing Columns\n",
    "        #Adding New column by concating the month day and year as date of birth\n",
    "\n",
    "    date_rectified_df.withColumn(\n",
    "        'DateOfBirth',\n",
    "        to_date(\n",
    "            concat_ws(\n",
    "                '-',\n",
    "                col('Year'),\n",
    "                col('Month'),\n",
    "                col('Day')\n",
    "            ),\n",
    "            'yyyy-MM-dd'\n",
    "        )\n",
    "    )\n",
    "\n",
    " # Creating quick dataframe\n",
    "# Uniform the year \n",
    "# Drop the Duplicates\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    spark = (\n",
    "        SparkSession.builder\n",
    "        .appName('mis transformations')\n",
    "        .master('local[*]')\n",
    "        .getOrCreate()\n",
    "    )\n",
    "\n",
    "    data = [\n",
    "        ('John', 'Doe', 28, 'New York',2006,12,12),\n",
    "        ('Jane', 'Smith', 34, 'Los Angeles',2010,30,12),\n",
    "        ('Sam', 'Brown', 22, 'Chicago',84,20,12),\n",
    "        ('Emily', 'Davis', 29, 'Houston',96,25,12),\n",
    "        ('Michael', 'Johnson', 31, 'Phoenix',98,31,12),\n",
    "        ('Jane', 'Smith', 34, 'Los Angeles',2010,30,12)\n",
    "    ]\n",
    "\n",
    "    schema = StructType([\n",
    "        StructField('FirstName',StringType()),\n",
    "        StructField('LastName',StringType()),\n",
    "        StructField('Age',IntegerType()),\n",
    "        StructField('City',StringType()),\n",
    "        StructField('Year',IntegerType()),\n",
    "        StructField('Day',IntegerType()),\n",
    "        StructField('Month',IntegerType())\n",
    "    ]\n",
    "    )\n",
    "\n",
    "    spark_df = spark.createDataFrame(\n",
    "        data,\n",
    "        schema = schema\n",
    "    )\n",
    "\n",
    "    # Rectifiy the Date issue; we can see the pattern that if the year is 2 digit then its mostly from 1900s\n",
    "\n",
    "    date_rectified_df = (\n",
    "        spark_df.withColumn(\n",
    "        'Year',\n",
    "        when(\n",
    "            length(col('Year')) == 2,\n",
    "            col('Year') + 1900\n",
    "        ).otherwise(\n",
    "            col('Year')\n",
    "        )\n",
    "    )\n",
    "    )\n",
    "\n",
    "    # Add a incremental unique id\n",
    "\n",
    "    unique_id_df = (\n",
    "        date_rectified_df.withColumn(\n",
    "            'UniqueID',\n",
    "            monotonically_increasing_id()\n",
    "        )\n",
    "    ).select(\n",
    "        'UniqueID',\n",
    "        'FirstName',\n",
    "        'LastName',\n",
    "        'Age',\n",
    "        'City',\n",
    "        'Year'\n",
    "    )\n",
    "\n",
    "    # Showing Type casting error\n",
    "    # Type casting is useful when we inherit the data from files with issues\n",
    "    # when we define the dataframe its good to create the schema as well as we created \n",
    "\n",
    "    data2 = [\n",
    "        ('John', 'Doe', 28, 'New York','2006'),\n",
    "        ('Jane', 'Smith', 34, 'Los Angeles','2010'),\n",
    "        ('Sam', 'Brown', 22, 'Chicago','84'),\n",
    "        ('Emily', 'Davis', 29, 'Houston','96'),\n",
    "        ('Michael', 'Johnson', 31, 'Phoenix','98'),\n",
    "        ('Jane', 'Smith', 34, 'Los Angeles','2010')\n",
    "    ]\n",
    "\n",
    "    spark_df2 = spark.createDataFrame(\n",
    "        data2,\n",
    "        ['FirstName','LastName','Age','City','Year']                \n",
    "        ).withColumn(\n",
    "            'Year',\n",
    "            when (\n",
    "                length(col('Year')) == 2,\n",
    "                col('Year') + 1900\n",
    "            ).otherwise(\n",
    "                col('Year')\n",
    "            )\n",
    "        )\n",
    "#+---------+--------+---+-----------+------+\n",
    "#|FirstName|LastName|Age|       City|  Year|\n",
    "#+---------+--------+---+-----------+------+\n",
    "#|     John|     Doe| 28|   New York|  2006|\n",
    "#|     Jane|   Smith| 34|Los Angeles|  2010|\n",
    "#|      Sam|   Brown| 22|    Chicago|1984.0|\n",
    "#|    Emily|   Davis| 29|    Houston|1996.0|\n",
    "#|  Michael| Johnson| 31|    Phoenix|1998.0|\n",
    "#|     Jane|   Smith| 34|Los Angeles|  2010|\n",
    "#+---------+--------+---+-----------+------+\n",
    "    # The transformation that happenend here as there incorrect datatype and automatic type promotion by spark\n",
    "    # The year is string when we performed arithmetic opetation spark sql engine prtomoted it to float and after opetation the column was demoted to string and decimals wasnt removed  \n",
    "    # Solution is the Casting method\n",
    "\n",
    "# 2 Ways:\n",
    "    # Casting so with transformation so Spark dooest automatically promote or demote the datatype\n",
    "\n",
    "    spark_df2 = spark.createDataFrame(\n",
    "        data2,\n",
    "        ['FirstName','LastName','Age','City','Year']                \n",
    "        ).withColumn(\n",
    "            'Year',\n",
    "            when (\n",
    "                length(col('Year')) == 2,\n",
    "                col('Year').cast(IntegerType()) + 1900\n",
    "            ).otherwise(\n",
    "                col('Year')\n",
    "            )\n",
    "        )\n",
    "\n",
    "# +---------+--------+---+-----------+----+\n",
    "# |FirstName|LastName|Age|       City|Year|\n",
    "# +---------+--------+---+-----------+----+\n",
    "# |     John|     Doe| 28|   New York|2006|\n",
    "# |     Jane|   Smith| 34|Los Angeles|2010|\n",
    "# |      Sam|   Brown| 22|    Chicago|1984|\n",
    "# |    Emily|   Davis| 29|    Houston|1996|\n",
    "# |  Michael| Johnson| 31|    Phoenix|1998|\n",
    "# |     Jane|   Smith| 34|Los Angeles|2010|\n",
    "# +---------+--------+---+-----------+----+\n",
    "    # You dont see the decimals anymore\n",
    "    # Recommended approach\n",
    "\n",
    "    # Second Approach Change the schema format with casting in the beginning post the defining of the dataframe\n",
    "    spark_df2 = spark.createDataFrame(\n",
    "    data2,\n",
    "    ['FirstName','LastName','Age','City','Year']                \n",
    "    ).withColumn(\n",
    "        'FirstName',col('FirstName').cast(StringType())\n",
    "    ).withColumn(\n",
    "        'LastName',col('LastName').cast(StringType())\n",
    "    ).withColumn(\n",
    "        'Age',col('Age').cast(IntegerType())\n",
    "    ).withColumn(\n",
    "        'City',col('City').cast(StringType())\n",
    "    ).withColumn(\n",
    "        'Year',col('Year').cast(IntegerType())\n",
    "    ).withColumn(\n",
    "        'Year',\n",
    "        when (\n",
    "            length(col('Year')) == 2,\n",
    "            col('Year') + 1900\n",
    "        ).otherwise(\n",
    "            col('Year')\n",
    "        )\n",
    "    )\n",
    "\n",
    "# +---------+--------+---+-----------+----+\n",
    "# |FirstName|LastName|Age|       City|Year|\n",
    "# +---------+--------+---+-----------+----+\n",
    "# |     John|     Doe| 28|   New York|2006|\n",
    "# |     Jane|   Smith| 34|Los Angeles|2010|\n",
    "# |      Sam|   Brown| 22|    Chicago|1984|\n",
    "# |    Emily|   Davis| 29|    Houston|1996|\n",
    "# |  Michael| Johnson| 31|    Phoenix|1998|\n",
    "# |     Jane|   Smith| 34|Los Angeles|2010|\n",
    "# +---------+--------+---+-----------+----+\n",
    "\n",
    "    # Adding and removing Columns and dropping duplicates\n",
    "        #Adding New column by concating the month day and year as date of birth\n",
    "\n",
    "    date_rectified_df.withColumn(\n",
    "        'DateOfBirth',\n",
    "        to_date(\n",
    "            concat_ws(\n",
    "                '-',\n",
    "                col('Year'),\n",
    "                col('Month'),\n",
    "                col('Day')\n",
    "            ),\n",
    "            'yyyy-MM-dd'\n",
    "        )\n",
    "    ).drop(\n",
    "        'Year',\n",
    "        'Month',\n",
    "        'Day'\n",
    "    ).dropDuplicates(\n",
    "        ['FirstName',\n",
    "        'DateOfBirth']\n",
    "    ).sort(\n",
    "        [col('FirstName').asc(),\n",
    "        col('DateOfBirth').asc()]\n",
    "    ).show() \n",
    "\n",
    "# Concatenated transforation result\n",
    "# +---------+--------+---+-----------+----+---+-----+-----------+\n",
    "# |FirstName|LastName|Age|       City|Year|Day|Month|DateOfBirth|\n",
    "# +---------+--------+---+-----------+----+---+-----+-----------+\n",
    "# |     John|     Doe| 28|   New York|2006| 12|   12| 2006-12-12|\n",
    "# |     Jane|   Smith| 34|Los Angeles|2010| 15|   12| 2010-12-15|\n",
    "# |      Sam|   Brown| 22|    Chicago|1984| 20|   12| 1984-12-20|\n",
    "# |    Emily|   Davis| 29|    Houston|1996| 25|   12| 1996-12-25|\n",
    "# |  Michael| Johnson| 31|    Phoenix|1998| 31|   12| 1998-12-31|\n",
    "# |     Jane|   Smith| 34|Los Angeles|2010| 30|   12| 2010-12-30|\n",
    "# +---------+--------+---+-----------+----+---+-----+-----------+\n",
    "\n",
    "#Drop Column and Duplicate results\n",
    "# +---------+--------+---+-----------+-----------+\n",
    "# |FirstName|LastName|Age|       City|DateOfBirth|\n",
    "# +---------+--------+---+-----------+-----------+\n",
    "# |    Emily|   Davis| 29|    Houston| 1996-12-25|\n",
    "# |     Jane|   Smith| 34|Los Angeles| 2010-12-30|\n",
    "# |     John|     Doe| 28|   New York| 2006-12-12|\n",
    "# |  Michael| Johnson| 31|    Phoenix| 1998-12-31|\n",
    "# |      Sam|   Brown| 22|    Chicago| 1984-12-20|\n",
    "# +---------+--------+---+-----------+-----------+\n",
    "\n",
    "# Sorted by first name and date of birth\n",
    "# +---------+--------+---+-----------+-----------+\n",
    "# |FirstName|LastName|Age|       City|DateOfBirth|\n",
    "# +---------+--------+---+-----------+-----------+\n",
    "# |    Emily|   Davis| 29|    Houston| 1996-12-25|\n",
    "# |     Jane|   Smith| 34|Los Angeles| 2010-12-30|\n",
    "# |     John|     Doe| 28|   New York| 2006-12-12|\n",
    "# |  Michael| Johnson| 31|    Phoenix| 1998-12-31|\n",
    "# |      Sam|   Brown| 22|    Chicago| 1984-12-20|\n",
    "# +---------+--------+---+-----------+-----------+\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8e87e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
