{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adc260c6",
   "metadata": {},
   "source": [
    "%md\n",
    "# Spark UDF\n",
    "- A User-Defined Function (UDF) in PySpark is used when you need to apply custom logic that cannot be easily expressed using built-in Spark SQL functions.\n",
    "- The functions has to be written in native python and wrapped in pyspark function for distributed usage.\n",
    "- UDFs allow you to wrap any Python function and use it with Spark DataFrames.\n",
    "- Steps\n",
    "  - Define the function:\n",
    "    def upper_case(name):\n",
    "    return name.upper()\n",
    "  - Register as UDF:\n",
    "    upper_udf = udf(upper_case, StringType())\n",
    "  - Apply UDF to DataFrame:\n",
    "    df.withColumn(\"name_upper\", upper_udf(df[\"name\"]))\n",
    "- UDFs are not optimized by Catalyst (Sparkâ€™s optimization engine).\n",
    "- They run in a separate Python process (via Py4J), which slows performance.\n",
    "\n",
    "## Why wrap the function:\n",
    "- PySpark needs to convert a normal Python function into a Spark-compatible expression that can be applied to a DataFrame column.\n",
    "- Spark runs distributed, Your Python function (e.g., upper_case) runs on the driver node.\n",
    "- Data lives on executor nodes.\n",
    "- Spark needs to serialize and ship your logic to all the executors.\n",
    "- So, udf() acts like a translator that Prepares the function for execution on distributed data and Manages type safety \n",
    "\n",
    "## Registering Function:\n",
    "- 2 ways one for dataframe col object and one for sql expression\n",
    "- The registeration process is difference\n",
    "- The dataframe UDF method : complete_date_udf = udf( flight_date_generator,DateType())\n",
    "  - will not register the udf to catalogue\n",
    "  - use this if you want to use the UDF in dataframe\n",
    "- For sql based : spark.udf.register(complete_date_udf,flight_date_generator,DateType())\n",
    "  - Register as sql function and creates entry in the catalogue\n",
    "  - Use this if you want to use the function in SQL expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0880a568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the dataset\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    spark = (\n",
    "        SparkSession.builder\n",
    "        .appName('Spark col transformation')\n",
    "        .getOrCreate()\n",
    "    )\n",
    "             \n",
    "\n",
    "    flights_df = (\n",
    "        spark.read\n",
    "        .format('csv')\n",
    "        .option('inferSchema','true')\n",
    "        .option('header','true')\n",
    "        .option('samplingRatio','0.001')\n",
    "        .load(\n",
    "            path = r'C:\\Users\\shubh\\OneDrive\\Documents\\Visual Studio 2017\\datasets\\flights.csv', # gotta download the flights dataset to work\n",
    "            encoding = 'utf-8'\n",
    "        )   \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d126162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+---------+----------+--------+--------+----+--------+\n",
      "|Origin|Dest|FlightNum|FlightDate|Max Year|Min Year|Year|Distance|\n",
      "+------+----+---------+----------+--------+--------+----+--------+\n",
      "|   IAD| TPA|      335|2008-01-03|    2008|    2008|2008|     810|\n",
      "|   IAD| TPA|     3231|2008-01-03|    2008|    2008|2008|     810|\n",
      "|   IND| BWI|      448|2008-01-03|    2008|    2008|2008|     515|\n",
      "|   IND| BWI|     1746|2008-01-03|    2008|    2008|2008|     515|\n",
      "|   IND| BWI|     3920|2008-01-03|    2008|    2008|2008|     515|\n",
      "|   IND| JAX|      378|2008-01-03|    2008|    2008|2008|     688|\n",
      "|   IND| LAS|      509|2008-01-03|    2008|    2008|2008|    1591|\n",
      "|   IND| LAS|      535|2008-01-03|    2008|    2008|2008|    1591|\n",
      "|   IND| MCI|       11|2008-01-03|    2008|    2008|2008|     451|\n",
      "|   IND| MCI|      810|2008-01-03|    2008|    2008|2008|     451|\n",
      "|   IND| MCO|      100|2008-01-03|    2008|    2008|2008|     828|\n",
      "|   IND| MCO|     1333|2008-01-03|    2008|    2008|2008|     828|\n",
      "|   IND| MDW|      829|2008-01-03|    2008|    2008|2008|     162|\n",
      "|   IND| MDW|     1016|2008-01-03|    2008|    2008|2008|     162|\n",
      "|   IND| MDW|     1827|2008-01-03|    2008|    2008|2008|     162|\n",
      "|   IND| MDW|     2272|2008-01-03|    2008|    2008|2008|     162|\n",
      "|   IND| PHX|      675|2008-01-03|    2008|    2008|2008|    1489|\n",
      "|   IND| PHX|     1144|2008-01-03|    2008|    2008|2008|    1489|\n",
      "|   IND| TPA|        4|2008-01-03|    2008|    2008|2008|     838|\n",
      "|   ISP| BWI|       54|2008-01-03|    2008|    2008|2008|     220|\n",
      "+------+----+---------+----------+--------+--------+----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "def flight_date_generator(year, month, day):\n",
    "    try:\n",
    "        return datetime.datetime.strptime(f\"{int(year):04d}{int(month):02d}{int(day):02d}\", \"%Y%m%d\").date()\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "complete_date_udf = udf( flight_date_generator,DateType())\n",
    "\n",
    "transformed_df = (\n",
    "  flights_df.withColumn(\n",
    "    'FlightDate',\n",
    "    complete_date_udf(\n",
    "      flights_df['Year'],\n",
    "      flights_df['Month'],\n",
    "      flights_df['DayofMonth']\n",
    "    )\n",
    "  ).withColumn(\n",
    "      'Max Year', year(col('FlightDate'))\n",
    "  ).withColumn(\n",
    "      'Min Year', year(col('FlightDate'))\n",
    "  ).select(\n",
    "    'Origin',\n",
    "    'Dest',\n",
    "    'FlightNum',\n",
    "    'FlightDate',\n",
    "    'Max Year',\n",
    "    'Min Year',\n",
    "    'Year',\n",
    "    'Distance'\n",
    "  )\n",
    ")\n",
    "\n",
    "transformed_df.show()\n",
    "\n",
    "#learnings:\n",
    "  # the function has to be in core python and not use the pyspark functions\n",
    "  # the withcolumn transformation has to be first as the select is an action\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20040522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+---------+----------+----+------+--------+\n",
      "|Origin|Dest|FlightNum|FlightDate|Year|Decade|Distance|\n",
      "+------+----+---------+----------+----+------+--------+\n",
      "|   IAD| TPA|      335|2008-01-03|2008| 2000s|     810|\n",
      "|   IAD| TPA|     3231|2008-01-03|2008| 2000s|     810|\n",
      "|   IND| BWI|      448|2008-01-03|2008| 2000s|     515|\n",
      "|   IND| BWI|     1746|2008-01-03|2008| 2000s|     515|\n",
      "|   IND| BWI|     3920|2008-01-03|2008| 2000s|     515|\n",
      "+------+----+---------+----------+----+------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# same transformation using case when and col object\n",
    "transformed_df.withColumn(\n",
    "    'Decade',\n",
    "    expr(\n",
    "        \"\"\"\n",
    "        Case \n",
    "            When Year between 2000 and 2010 Then '2000s'\n",
    "            else NULL\n",
    "        END\n",
    "        \"\"\"\n",
    "    )\n",
    "    ).select(\n",
    "    'Origin',\n",
    "    'Dest',\n",
    "    'FlightNum',\n",
    "    'FlightDate',\n",
    "    'Year',\n",
    "    'Decade',\n",
    "    'Distance'\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97520172",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
