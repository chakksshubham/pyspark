{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abb9991b",
   "metadata": {},
   "source": [
    "# Hadoop Distributed Platform\n",
    "\n",
    "## Overview\n",
    "\n",
    "- A solution to new data processing problems.\n",
    "- Designed in layers:\n",
    "  - **YARN** – Cluster operating system.\n",
    "  - **HDFS** – Distributed file system.\n",
    "  - **MapReduce** – Distributed computing using Java.\n",
    "\n",
    "- Hadoop was created as an operating system for distributed cluster systems.\n",
    "- Clusters need an OS to manage CPU, memory, and disk — Hadoop fulfills this by enabling the use of a cluster as a single large computer.\n",
    "\n",
    "### Key Components\n",
    "\n",
    "#### YARN (Yet Another Resource Negotiator)\n",
    "\n",
    "- Works as a cluster manager for managing distributed clusters and resource allocation.\n",
    "\n",
    "#### HDFS (Hadoop Distributed File System)\n",
    "\n",
    "- Provides distributed storage for large files across cluster storage systems.\n",
    "\n",
    "#### MapReduce\n",
    "\n",
    "- Allows writing processing applications in Java and executing them across clusters in parallel.\n",
    "- You can write the data processing logic as you would for a monolithic system, but Hadoop distributes and parallelizes the execution.\n",
    "\n",
    "---\n",
    "\n",
    "## Hadoop Architecture\n",
    "\n",
    "### Topics to Cover\n",
    "\n",
    "- What is Hadoop and how it works.\n",
    "- Where it originated.\n",
    "- Challenges it faces.\n",
    "- Introduction to Apache Spark and how it solves Hadoop’s limitations.\n",
    "\n",
    "---\n",
    "\n",
    "## What is Hadoop?\n",
    "\n",
    "A distributed data processing platform that includes three core components:\n",
    "\n",
    "### YARN\n",
    "\n",
    "- **Yet Another Resource Manager** – the cluster resource manager, often referred to as a cluster OS.\n",
    "- Allows running multiple applications by sharing resources among them.\n",
    "- Uses a **master-slave architecture**.\n",
    "\n",
    "#### Components\n",
    "\n",
    "- **Resource Manager (RM)** – Installed on the master node.\n",
    "- **Node Manager (NM)** – Installed on slave nodes.\n",
    "- **Application Master (AM)** – Runs per application to manage its lifecycle.\n",
    "\n",
    "#### Architecture\n",
    "\n",
    "- Suppose we create a cluster with 5 computers.\n",
    "- Install Hadoop on all five systems.\n",
    "- One system becomes the **master** with RM, others become **slaves** with NMs.\n",
    "- NMs continuously send status updates to the RM.\n",
    "- Applications are submitted to YARN (the RM).\n",
    "- RM assigns the job to an NM, which creates a **container** for the app.\n",
    "- A container holds the required resources (CPU, memory) for the application.\n",
    "- Each application runs in a separate AM container.\n",
    "\n",
    "---\n",
    "\n",
    "### HDFS\n",
    "\n",
    "- **Hadoop Distributed File System** – Handles distributed storage.\n",
    "\n",
    "#### Components\n",
    "\n",
    "- **Name Node (NN)** – Installed on the master.\n",
    "- **Data Node (DN)** – Installed on slave nodes.\n",
    "\n",
    "#### Architecture\n",
    "\n",
    "- HDFS stores and retrieves large files in a distributed fashion.\n",
    "- Example: copying a large dataset\n",
    "  - The command goes to NN, which sends instructions to DNs.\n",
    "  - The data is split into smaller **blocks**, distributed across DNs.\n",
    "  - NN stores metadata (filename, directory, block IDs, etc.).\n",
    "- When reading, NN fetches metadata and arranges the file from blocks stored in DNs.\n",
    "\n",
    "---\n",
    "\n",
    "### MapReduce Programming Model and Framework\n",
    "\n",
    "#### Programming Model\n",
    "\n",
    "- A conceptual approach for writing distributed computation code.\n",
    "- Breaks a program into two stages:\n",
    "  - **Map**: Processes and computes data at the block level.\n",
    "  - **Reduce**: Aggregates and summarizes the outputs from map functions.\n",
    "\n",
    "#### Programming Framework\n",
    "\n",
    "- The actual infrastructure and libraries that run the distributed MapReduce code.\n",
    "- Though considered outdated now, understanding it is still important.\n",
    "\n",
    "#### Example Use Case\n",
    "\n",
    "- Reading a 20TB file might take days sequentially (e.g., 3–4 hours per TB).\n",
    "- Using MapReduce:\n",
    "  - Each node processes its own block in parallel.\n",
    "  - Map function counts rows in each file block.\n",
    "  - Reduce function sums up all block-level counts to get the total.\n",
    "\n",
    "---\n",
    "\n",
    "### MapReduce Execution in Practice\n",
    "\n",
    "- A MapReduce job request is submitted to the RM.\n",
    "- RM tells NM to start an AM and launch the job.\n",
    "- The framework coordinates with RM to:\n",
    "  - Launch multiple AM containers (e.g., 14 for 14 nodes).\n",
    "  - Run the **Map** phase in parallel across nodes.\n",
    "  - Gather the results and initiate the **Reduce** phase.\n",
    "- The framework ensures efficient distribution and fault tolerance across the cluster.\n",
    "\n",
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "Hadoop revolutionized data processing by shifting from monolithic systems to distributed computing. It provides a scalable, cost-effective solution to big data challenges using its core components: YARN, HDFS, and MapReduce. While newer tools like Apache Spark offer performance improvements, Hadoop's design remains foundational to understanding modern distributed data systems.\n",
    "\n",
    "---\n",
    "## Problems with Hadoop\n",
    "\n",
    "- Performance (hivesql which was introduced to solve developer hardship to write base map reduce program were slow).\n",
    "- Hard to develop as map reduce was hard to write.\n",
    "- Only avl in Java.\n",
    "- Cloud platform emerged that led to easier storage increasing as for hadoop physical systems were needed where as cloud was digital and was cheap.\n",
    "- Industry also developed other container techs like docker kubernetes.\n",
    "-  Thats where Apache Spark came into existence\n",
    "    - faster performance\n",
    "    - offered sql but faster\n",
    "    - ease of development with scala, python, java\n",
    "    - supported cloud like S3\n",
    "    - designed in way to work with multiple RM and Container.\n",
    "\n",
    "- Spark was initally used as improvement to hadoop but later solved all the issues with hadoop and thus became stand alone.\n",
    "- Now spark can be used with Hadoop and without Hadoop including evertyhing that hadoop has to offer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b00191",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
